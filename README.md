# TamkeenEd â€“ Empowering Inclusive Education

**Senior Capstone Project â€“ SE499**  
**Supervised by:** Dr. Basmah Alkanjr  
**Team Members:**  
- Aljazi Alghunaim
- Nouf Almojel  
- Lara AlBaijan  
- Rose Alraba  
- Manar Altuwaim  

---

## Overview

**TamkeenEd** is a mobile study companion designed to promote educational equity by transforming traditional learning materials into accessible formats for students with ADHD, visual impairments, and hearing impairments.  
This project aligns with the goals of **Saudi Vision 2030**, specifically in the domains of **digital transformation** and **inclusive education**.

Developed as part of the **SE499 Software Engineering Design and Development** course, TamkeenEd leverages AI to provide personalized, accessible learning experiences.

---

## Objectives

-  Provide accessible tools for diverse learning needs
-  Support ADHD learners with focus timers, flashcards, and summaries
-  Enable text-to-speech and high-contrast UI for visually impaired students
-  Provide transcription tools for hearing-impaired users
-  Deliver distraction-free, intuitive navigation for all

---

##  Tech Stack

| Technology       | Role in Project                                |
|------------------|-------------------------------------------------|
| **Flutter (Dart)**   | Cross-platform mobile app framework          |
| **Firebase**         | Authentication, storage, and real-time sync  |
| **Gemini AI**        | Generate smart summaries and flashcards      |
| **Deepgram**         | Audio & video transcription services         |
| **Android Studio**   | IDE for implementation and testing           |

---

##  Sprint-Based Feature Development

###  Sprint 1 â€“ Authentication & Navigation
- Secure sign-up/login with email and password
- Password reset via email
- Session persistence across app usage
- Core navigation: Home, Modules, Profile

###  Sprint 2 â€“ ADHD Support
- AI-generated flashcards (questionâ€“answer pairs)
- Smart content summarization
- Focus timer with clean UI and visual feedback

###  Sprint 3 â€“ Visual Accessibility
- High-contrast and large/bold text modes
- Screen-reader navigation
- Text-to-speech for summaries and flashcards
- Accessible profile editing

###  Sprint 4 â€“ Hearing Accessibility
- Upload lecture videos or audio files
- Auto transcription via Deepgram
- Transcription library with persistent access
- Progress tracking, FAQ, and feedback module

---

## Testing Methodology

Each sprint followed a structured test cycle:
- ** Unit Testing (UTC)**: Validated individual components and edge cases
- **Integration Testing (ITC)**: Ensured smooth data and logic flow across modules
- **Regression Testing**: Re-verified functionality after merges and bug fixes

> Over 60 test cases passed successfully across all modules.

---

## Results

- Stable user authentication and routing  
- Accurate, fast AI summaries and flashcards  
- Functional accessibility modes across screens  
- Reliable Arabic/English audio transcription  
- Responsive performance during uploads and AI tasks  
- Positive feedback from user testing and peer reviews

---

## Future Directions

- iOS and responsive web version
- Full support for Arabic UI and RTL layout
- Educator dashboard for classroom management
- Improved AI for summarization and glossary creation
- Live captioning with improved word error rate (WER)

---

## Academic Acknowledgment

This project is part of our **senior graduation requirement** for the SE499 course at [Your University Name].  
It was developed under the guidance of **Dr. Basmah Alkanjr** and reflects our commitment to advancing accessible technology for education.

---

## ðŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

---
